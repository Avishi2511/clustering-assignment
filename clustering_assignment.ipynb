{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb_Q6U0bGvII"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.23.5  # Use a stable version that works with PyCaret\n",
        "!pip install --upgrade pycaret"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.clustering import *\n",
        "import pandas as pd\n",
        "\n",
        "myDataSet = pd.read_csv(\"/content/forestfires.csv\")\n",
        "\n",
        "results = pd.DataFrame(columns=[\"Preprocessing\", \"Number of Clusters\", \"Silhouette\", \"Calinski-Harabasz\", \"Davies-Bouldin\"])\n",
        "\n",
        "num_clusters = [3, 4, 5]\n",
        "\n",
        "def get_parameters(num_clusters, preprocessing):\n",
        "    for num in num_clusters:\n",
        "        model = create_model('kmeans', num_clusters=num)\n",
        "        prediction = assign_model(model)\n",
        "        performance = pull()\n",
        "\n",
        "        results.loc[len(results)] = [\n",
        "            preprocessing,\n",
        "            num,\n",
        "            performance['Silhouette'][0],\n",
        "            performance['Calinski-Harabasz'][0],\n",
        "            performance['Davies-Bouldin'][0]\n",
        "        ]\n",
        "\n",
        "def run_all():\n",
        "    print(\"For no data processing\")\n",
        "    setup(data=myDataSet, verbose=False)\n",
        "    get_parameters(num_clusters, \"No Data Processing\")\n",
        "\n",
        "    print(\"For using normalization\")\n",
        "    setup(data=myDataSet, normalize=True, normalize_method='zscore', verbose=False)\n",
        "    get_parameters(num_clusters, \"Normalization\")\n",
        "\n",
        "    print(\"For using transformation\")\n",
        "    setup(data=myDataSet, transformation=True, transformation_method='yeo-johnson', verbose=False)\n",
        "    get_parameters(num_clusters, \"Transformation\")\n",
        "\n",
        "    print(\"For using PCA\")\n",
        "    setup(data=myDataSet, pca=True, pca_method='linear', verbose=False)\n",
        "    get_parameters(num_clusters, \"PCA\")\n",
        "\n",
        "    print(\"For using N+T\")\n",
        "    setup(data=myDataSet, normalize=True, normalize_method='zscore', transformation=True,\n",
        "          transformation_method='yeo-johnson', verbose=False)\n",
        "    get_parameters(num_clusters, \"N+T\")\n",
        "\n",
        "    print(\"For using N+T+PCA\")\n",
        "    setup(data=myDataSet, normalize=True, normalize_method='zscore', transformation=True,\n",
        "          transformation_method='yeo-johnson', pca=True, pca_method='linear', verbose=False)\n",
        "    get_parameters(num_clusters, \"N+T+PCA\")\n",
        "\n",
        "run_all()\n",
        "\n",
        "print(\"\\nClustering Performance Metrics:\")\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "e5fYmLsRTIJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.clustering import *\n",
        "import pandas as pd\n",
        "\n",
        "myDataSet = pd.read_csv(\"/content/forestfires.csv\")\n",
        "\n",
        "results = pd.DataFrame(columns=[\"Preprocessing\", \"Number of Clusters\", \"Silhouette\", \"Calinski-Harabasz\", \"Davies-Bouldin\"])\n",
        "\n",
        "num_clusters = [3, 4, 5]\n",
        "\n",
        "def get_parameters(num_clusters, preprocessing):\n",
        "    for num in num_clusters:\n",
        "        model = create_model('hclust', num_clusters=num)\n",
        "        prediction = assign_model(model)\n",
        "        performance = pull()\n",
        "\n",
        "        results.loc[len(results)] = [\n",
        "            preprocessing,\n",
        "            num,\n",
        "            performance['Silhouette'][0],\n",
        "            performance['Calinski-Harabasz'][0],\n",
        "            performance['Davies-Bouldin'][0]\n",
        "        ]\n",
        "\n",
        "print(\"For no data processing\")\n",
        "setup(data=myDataSet, verbose=False)\n",
        "get_parameters(num_clusters, \"No Data Processing\")\n",
        "\n",
        "print(\"For using normalization\")\n",
        "setup(data=myDataSet, normalize=True, normalize_method='zscore', verbose=False)\n",
        "get_parameters(num_clusters, \"Normalization\")\n",
        "\n",
        "print(\"For using transformation\")\n",
        "setup(data=myDataSet, transformation=True, transformation_method='yeo-johnson', verbose=False)\n",
        "get_parameters(num_clusters, \"Transformation\")\n",
        "\n",
        "print(\"For using PCA\")\n",
        "setup(data=myDataSet, pca=True, pca_method='linear', verbose=False)\n",
        "get_parameters(num_clusters, \"PCA\")\n",
        "\n",
        "print(\"For using N+T\")\n",
        "setup(data=myDataSet, normalize=True, normalize_method='zscore', transformation=True,\n",
        "      transformation_method='yeo-johnson', verbose=False)\n",
        "get_parameters(num_clusters, \"N+T\")\n",
        "\n",
        "print(\"For using N+T+PCA\")\n",
        "setup(data=myDataSet, normalize=True, normalize_method='zscore', transformation=True,\n",
        "      transformation_method='yeo-johnson', pca=True, pca_method='linear', verbose=False)\n",
        "get_parameters(num_clusters, \"N+T+PCA\")\n",
        "\n",
        "print(\"\\nClustering Performance Metrics:\")\n",
        "print(results)\n",
        "\n"
      ],
      "metadata": {
        "id": "afsqqEZ6VQk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.clustering import *\n",
        "import pandas as pd\n",
        "\n",
        "myDataSet = pd.read_csv(\"/content/forestfires.csv\")\n",
        "\n",
        "results = pd.DataFrame(columns=[\"Preprocessing\", \"Number of Clusters\", \"Silhouette\", \"Calinski-Harabasz\", \"Davies-Bouldin\"])\n",
        "\n",
        "num_clusters = [3, 4, 5]\n",
        "\n",
        "def get_parameters(num_clusters, preprocessing):\n",
        "    for num in num_clusters:\n",
        "        model = create_model('meanshift', num_clusters=num)\n",
        "        prediction = assign_model(model)\n",
        "        performance = pull()\n",
        "\n",
        "        results.loc[len(results)] = [\n",
        "            preprocessing,\n",
        "            num,\n",
        "            performance['Silhouette'][0],\n",
        "            performance['Calinski-Harabasz'][0],\n",
        "            performance['Davies-Bouldin'][0]\n",
        "        ]\n",
        "\n",
        "print(\"For no data processing\")\n",
        "kMeanClusteringParameters = setup(data=myDataSet, verbose=False)\n",
        "get_parameters(num_clusters, \"No Data Processing\")\n",
        "\n",
        "print(\"For using normalization\")\n",
        "normparam = setup(data=myDataSet, normalize=True, normalize_method='zscore', verbose=False)\n",
        "get_parameters(num_clusters, \"Normalization\")\n",
        "\n",
        "print(\"For using transformation\")\n",
        "transformparam = setup(data=myDataSet, transformation=True, transformation_method='yeo-johnson', verbose=False)\n",
        "get_parameters(num_clusters, \"Transformation\")\n",
        "\n",
        "print(\"For using PCA\")\n",
        "pcaparam = setup(data=myDataSet, pca=True, pca_method='linear', verbose=False)\n",
        "get_parameters(num_clusters, \"PCA\")\n",
        "\n",
        "print(\"For using N+T\")\n",
        "ntparam = setup(data=myDataSet, transformation=True, normalize=True, normalize_method='zscore',\n",
        "                transformation_method='yeo-johnson', verbose=False)\n",
        "get_parameters(num_clusters, \"N+T\")\n",
        "\n",
        "print(\"For using N+T+PCA\")\n",
        "ntpcaparam = setup(data=myDataSet, transformation=True, normalize=True, pca=True,\n",
        "                   normalize_method='zscore', transformation_method='yeo-johnson',\n",
        "                   pca_method='linear', verbose=False)\n",
        "get_parameters(num_clusters, \"N+T+PCA\")\n",
        "\n",
        "print(\"\\nClustering Performance Metrics:\")\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "gYNKgp5BeV0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "t_kmeans=setup(data=myDataSet,transformation = True, transformation_method = 'yeo-johnson', verbose=False)\n",
        "KMeanModel = create_model('kmeans', num_clusters=4)\n",
        "evaluate_model(KMeanModel)\n",
        "plot_model(KMeanModel, plot='cluster')"
      ],
      "metadata": {
        "id": "q8YaqDK1fJcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hier=setup(data=myDataSet,transformation = True,pca = True, pca_method = 'linear', verbose=False)\n",
        "hclustModel = create_model('hclust', num_clusters=4)\n",
        "evaluate_model(hclustModel)\n",
        "plot_model(hclustModel, plot='cluster')"
      ],
      "metadata": {
        "id": "k-NRxSqdkptN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meanshift = setup(data=myDataSet, verbose=False)\n",
        "meanshiftModel = create_model('meanshift', num_clusters=3)\n",
        "evaluate_model(meanshiftModel)\n",
        "plot_model(meanshiftModel, plot='cluster')"
      ],
      "metadata": {
        "id": "BPHPxa0clQne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4uFs8wMWlnGM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}